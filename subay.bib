@article{Amosa2023,
  title     = {Multi-camera multi-object tracking: A review of current trends and future advances},
  author    = {Amosa, Temitope Ibrahim and Sebastian, Patrick and Izhar, Lila Iznita and Ibrahim, Oladimeji and Ayinla, Lukman Shehu and Bahashwan, Abdulrahman Abdullah and Bala, Abubakar and Samaila, Yau Alhaji},
  journal   = {Neurocomputing},
  publisher = {Elsevier BV},
  volume    =  {552},
  number    =  {126558},
  pages     = {126558},
  month     =  {October},
  year      =  {2023},
  copyright = {http://creativecommons.org/licenses/by/4.0/},
  language  = {en}
}
@article{Chen2022,
  title     = {Research on pedestrian detection and DeepSort tracking in
               front of intelligent vehicle based on deep learning},
  author    = {Chen, Xuewen and Jia, Yuanpeng and Tong, Xiaoqi and Li, Zirou},
  abstract  = {In order to improve the tracking failure caused by small-target pedestrians and partially blocked pedestrians in dense crowds in complex environments, a pedestrian target detection and tracking method for an intelligent vehicle was proposed based on deep learning. On the basis of the YOLO detection model, the channel attention module and spatial attention module were introduced and were joined to the back of the backbone network Darknet-53 in order to achieve weight amplification of important feature information in channel and space dimensions and improve the representation ability of the model for important feature information. Based on the improved YOLO network, the flow of the DeepSort pedestrian tracking method was designed and the Kalman filter algorithm was used to estimate the pedestrian motion state. The Mahalanobis distance and apparent feature were used to calculate the similarity between the detection frame and the predicted pedestrian trajectory; the Hungarian algorithm was used to achieve the optimal matching of pedestrian targets. Finally, the improved YOLO pedestrian detection model and the DeepSort pedestrian tracking method were verified in the same experimental environment. The verification results showed that the improved model can improve the detection accuracy of small-target pedestrians, effectively deal with the problem of target occlusion, reduce the rate of missed detection and false detection of pedestrian targets, and improve the tracking failure caused by occlusion.},
  journal   = {Sustainability},
  publisher = {MDPI AG},
  volume    =  {14},
  number    =  {15},
  pages     = {9281},
  month     =  {July},
  year      =  {2022},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  language  = {en}
}
@article{Cobos2019,
  title     = {Retail traffic-flow analysis using a fast multi-object detection
               and tracking system},
  booktitle = {Applications of Computational Intelligence},
  author    = {Cobos, Richard and Hernandez, Jefferson and Abad, Andres G},
  publisher = {Springer International Publishing},
  pages     = {29--39},
  series    = {Communications in computer and information science},
  year      =  {2019},
  address   = {Cham}
}
@article{Erlina2023,
  title     = {A YOLO algorithm-based visitor detection system for small retail stores using single board computer},
  author    = {Erlina, Tati and Fikri, Muhammad},
  abstract  = {In Indonesia, assistance for small enterprises has grown in recent years. However, a monitoring system is required to support these enterprises and ensure their expansion and survival. Using a single-board computer and the YOLO algorithm, we construct a visitor tracking system in this study to meet this demand. To capture objects and categorize them as human or non-human, we employ the YOLOv4-tiny model, which has a mAP of 89.21\%. Human visitors are welcomed with the use of a speaker. A telegraph bot that notifies the owner of the retail establishment of the visitor's presence also makes the presumption as to whether the visitor is a potential customer or an intruder. Our research demonstrates that the created monitoring system effectively recognizes and categorizes visits, enabling retail store owners to make defensible choices regarding visitor interaction and security precautions. Small business owners can save personnel costs while still maintaining high levels of client engagement and security. The theoretical application of this research is the creation of a visitor monitoring system that is affordable and may be used in small enterprises, particularly in Indonesia. The practical ramifications of our research include the possibility for small retail business owners to boost profits by lowering labor expenses while raising customer satisfaction and security. The importance of our study lies in its role in creating a monitoring system that will support small enterprises and increase their sustainability.},
  journal   = {Journal of Applied Engineering and Technological Science (JAETS)},
  publisher = {Yayasan Riset dan Pengembangan Intelektual},
  volume    =  {4},
  number    =  {2},
  pages     = {908--920},
  month     =  {June},
  year      =  {2023}
}
@article{Kim2019,
  title     = {Location-based tracking data and customer movement pattern analysis for sustainable fashion business},
  author    = {Kim, Jonghyuk and Hwangbo, Hyunwoo and Kim, Sung Jun and Kim, Soyean},
  abstract  = {Retailers need accurate movement pattern analysis of human-tracking data to maximize the space performance of their stores and to improve the sustainability of their business. However, researchers struggle to precisely measure customers' movement patterns and their relationships with sales. In this research, we adopt indoor positioning technology, including wireless sensor devices and fingerprinting techniques, to track customers' movement patterns in a fashion retail store over four months. Specifically, we conducted three field experiments in three different timeframes. In each experiment, we rearranged one element of the visual merchandising display (VMD) to track and compare customer movement patterns before and after the rearrangement. For the analysis, we connected customers' discrete location data to identify meaningful patterns in customers' movements. We also used customers' location and time information to match identified movement pattern data with sales data. After classifying individuals' movements by time and sequences, we found that stay time in a particular zone had a greater impact on sales than the total stay time in the store. These results challenge previous findings in the literature that suggest that the longer customers stayed in a store, the more they purchase. Further, the results confirmed that effective store rearrangement could change not only customer movement patterns but also overall sales of store zones. This research can be a foundation for various practical applications of tracking data technologies.},
  journal   = {Sustainability},
  publisher = {MDPI AG},
  volume    =  {11},
  number    =  {22},
  pages     = {6209},
  month     =  {November},
  year      =  {2019},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  language  = {en}
}
@article{Kulkarni2023,
  title     = {Utilizing gen AI and Computer Vision for applications in the retail sector},
  author    = {Kulkarni, Nilesh and Bansal, Saurav},
  abstract  = {In this paper we provided a perspective on the integration of Artificial Intelligence (AI) and Computer Vision in the retail sector, highlighting their transformative potential in reshaping industry dynamics. It delves into the multifaceted applications of AI in retail, including inventory management, personalized shopping experiences, dynamic outreach, and conversational support, underscoring how these technologies drive customer engagement, operational efficiency, and innovation in product and service offerings. Moreover, the study explores the role of Computer Vision in revolutionizing retail experiences through self-checkout systems, inventory management, store layout optimization, and AI-based loss prevention. Emphasizing the necessity of adopting these technologies, the paper contends that AI and Computer Vision are not mere competitive advantages but crucial for maintaining relevance in the swiftly evolving retail landscape. The strategic integration of these technologies presents significant opportunities for growth and differentiation, although it necessitates substantial investment in resources and workforce upskilling.},
  journal   = {J Arti Inte \& Cloud Comp},
  publisher = {Scientific Research and Community Ltd.},
  pages     = {1--7},
  month     =  {December},
  year      =  {2023}
}
@article{Li2023,
  title = {Cross-camera multi-object tracking based on person re-identification and spatial-temporal constraints},
  author = {Li, Jiayue and YanPiao, N.},
  abstract = {Abstract In order to reduce the influence of occlusion on the overall feature representation of tracks and improve the accuracy of track correlation between cameras, this paper proposes a cross camera multi-target tracking method based on person appearance and spatial-temporal constraints: a new cross-camera multi-object tracking framework is constructed. Then the person spatial-temporal probability model is established. Finally, the spatial-temporal probability model and the person appearance similarity are jointly measured and the person trajectory correlation under cross-camera is completed by using data correlation; Comparative experiments on the dataset proved that the method is effective.},
  journal = {J. Phys. Conf. Ser.},
  publisher = {IOP Publishing},
  volume = {2492},
  number = {1},
  pages = {012032},
  month = {May},
  year = {2023},
  copyright = {http://creativecommons.org/licenses/by/3.0/}
}
@article{Xie2024,
  title           = {A robust online multi-camera people tracking system with geometric consistency and state-aware re-ID correction},
  booktitle       = {2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  author          = {Xie, Zhenyu and Ni, Zelin and Yang, Wenjie and Zhang, Yuang and Chen, Yihang and Zhang, Yang and Ma, Xiao},
  publisher       = {IEEE},
  pages           = {7007--7016},
  month           =  {June},
  year            =  {2024},
  conference      = {2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  location        = {Seattle, WA, USA}
}
@article{Xu2021,
  title     = {Multi-view feature fusion for person re-identification},
  author    = {Xu, Yinsong and Jiang, Zhuqing and Men, Aidong and Wang, Haiying
               and Luo, Haiyong},
  journal   = {Knowl. Based Syst.},
  publisher = {Elsevier BV},
  volume    =  {229},
  number    =  {107344},
  pages     = {107344},
  month     =  {October},
  year      =  {2021},
  copyright = {http://creativecommons.org/licenses/by-nc-nd/4.0/},
  language  = {en}
}
@article{Cabahug2023,
  title = {Customer Counting and Mapping for Intelligent Retail Environment using Computer Vision},
  author = {Cabahug, Jhon Lloyd and Gulle, Anferny Glenn and Macarayo, Dave and Perez, Leander Danilo},
  publisher = {University of Science and Technology of Southern Philippines - CDO},
  year = {2023},
  address = {Cagayan de Oro City, Philippines},
}
@article{Suljagic2022,
author = {Suljagic, Harun and Bayraktar, Ertuğrul and Celebi, Numan},
year = {2022},
month = {06},
title = {Similarity based person re-identification for multi-object tracking using deep Siamese network},
volume = {34},
journal = {Neural Computing and Applications},
doi = {10.1007/s00521-022-07456-2}
}
@misc{Sun2022, 
  title={CUSTOMER CONSUMER PREFERENCES RESEARCH.CASE YUMYUM BAKING OY},
  url={https://www.theseus.fi/bitstream/handle/10024/788057/Sun_Xiaodan.pdf;jsessionid=6CA528C7C830D09E72601DD32F6DC6A2?sequence=2}, 
  journal={theseus}, 
  author={Sun, Xiaodan}, 
  year={2022}
}
@misc{Visailabs2021, 
  title = {Evaluating multiple object tracking accuracy and performance metrics in a real-time setting}, 
  url = {https://visailabs.com/evaluating-multiple-object-tracking-accuracy-and-performance-metrics-in-a-real-time-setting}, 
  journal = {VisAI Labs}, 
  author = {Visailabs}, 
  year = {2021}, 
  month = {May}
}
@article{Shili2024,
  author = {Shili, Mohamed and Jayasingh, Suresh and Hammedi, Salah},
  title = {Advanced Customer Behavior Tracking and Heatmap Analysis with YOLOv5 and DeepSORT in Retail Environment},
  journal = {Electronics},
  volume = {13},
  number = {23},
  pages = {4730},
  year = {2024},
  doi = {10.3390/electronics13234730},
  url = {https://doi.org/10.3390/electronics13234730},
}
@INPROCEEDINGS{Han2023,
  author={Han, Xiaotian and You, Quanzeng and Wang, Chunyu and Zhang, Zhizheng and Chu, Peng and Hu, Houdong and Wang, Jiang and Liu, Zicheng},
  booktitle={2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  title={MMPTRACK: Large-scale Densely Annotated Multi-camera Multiple People Tracking Benchmark}, 
  year={2023},
  volume={},
  number={},
  pages={4849-4858},
  keywords={Training;Adaptation models;Three-dimensional displays;Benchmark testing;Cameras;Data models;Sensor systems;Algorithms: Video recognition and understanding (tracking;action recognition;etc.)},
  doi={10.1109/WACV56688.2023.00484}
}
@misc{GeeksforGeeks2025,
  title = {Residual Networks (ResNet) – Deep Learning},
  author = {{GeeksforGeeks}},
  year = {2025},
  month = {January},
  url = {https://www.geeksforgeeks.org/residual-networks-resnet-deep-learning/},
  note = {Accessed: 2025-04-23}
}
@misc{Boujou2022,
  author       = {Boujou, M.},
  title        = {Omni-Scale Feature Learning for Person Re-Identification},
  year         = {2022},
  month        = mar,
  url          = {https://medium.com/@moncefboujou96/omni-scale-feature-learning-for-person-re-identification-6e09df1c9a1a},
  note         = {Accessed: 2025-04-23}
}
@article{Artamonov2018,
doi = {10.1088/1742-6596/1096/1/012086},
url = {https://dx.doi.org/10.1088/1742-6596/1096/1/012086},
year = {2018},
month = {sep},
publisher = {IOP Publishing},
volume = {1096},
number = {1},
pages = {012086},
author = {Artamonov, N. and Yakimov, P.},
title = {Towards Real-Time Traffic Sign Recognition via YOLO on a Mobile GPU},
journal = {Journal of Physics: Conference Series},
abstract = {Classification of objects in the video stream with the help of deep learning has gained immense popularity nowadays. Considering many systems solving the classification problem, the mobility is often required. This paper proposes an implementation of the YOLO (You Only Look Once) convolutional neural network to solve the problem of classification of traffic signs on the mobile platform NVIDIA Jetson. The main feature of this platform is the availability of mobile graphics processor NVIDIA Tegra, which allows high-performance computing with low power consumption. The implemented algorithm of the YOLO CNN neural network allows solving the problem of the classification of traffic signs in a continuous video stream with decent accuracy and speed, and the NVIDIA Jetson platform provides mobility of the system.}
}

@Article{Fei2023,
AUTHOR = {Fei, Lunlin and Han, Bing},
TITLE = {Multi-Object Multi-Camera Tracking Based on Deep Learning for Intelligent Transportation: A Review},
JOURNAL = {Sensors},
VOLUME = {23},
YEAR = {2023},
NUMBER = {8},
ARTICLE-NUMBER = {3852},
URL = {https://www.mdpi.com/1424-8220/23/8/3852},
PubMedID = {37112193},
ISSN = {1424-8220},
ABSTRACT = {Multi-Objective Multi-Camera Tracking (MOMCT) is aimed at locating and identifying multiple objects from video captured by multiple cameras. With the advancement of technology in recent years, it has received a lot of attention from researchers in applications such as intelligent transportation, public safety and self-driving driving technology. As a result, a large number of excellent research results have emerged in the field of MOMCT. To facilitate the rapid development of intelligent transportation, researchers need to keep abreast of the latest research and current challenges in related field. Therefore, this paper provide a comprehensive review of multi-object multi-camera tracking based on deep learning for intelligent transportation. Specifically, we first introduce the main object detectors for MOMCT in detail. Secondly, we give an in-depth analysis of deep learning based MOMCT and evaluate advanced methods through visualisation. Thirdly, we summarize the popular benchmark data sets and metrics to provide quantitative and comprehensive comparisons. Finally, we point out the challenges faced by MOMCT in intelligent transportation and present practical suggestions for the future direction.},
DOI = {10.3390/s23083852}
}
@misc{Ultralytics2025,
author = {Ultralytics},
month = {3},
title = {Model comparisons: Choose the best object detection model for your project},
year = {2025},
url = {https://docs.ultralytics.com/compare/},
}
@misc{Ultralytics2025a,
	author = {Ultralytics},
	month = {3},
	title = {YOLOV10},
	year = {2025},
	url = {https://docs.ultralytics.com/models/yolov10/#performance},
}
@article{Brooke1995,
author = {Brooke, John},
year = {1995},
month = {11},
pages = {},
title = {SUS: A quick and dirty usability scale},
volume = {189},
journal = {Usability Eval. Ind.}
}
@INPROCEEDINGS{Zheng2015,
  author={Zheng, Liang and Shen, Liyue and Tian, Lu and Wang, Shengjin and Wang, Jingdong and Tian, Qi},
  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Scalable Person Re-identification: A Benchmark}, 
  year={2015},
  volume={},
  number={},
  pages={1116-1124},
  abstract={This paper contributes a new high quality dataset for person re-identification, named "Market-1501". Generally, current datasets: 1) are limited in scale, 2) consist of hand-drawn bboxes, which are unavailable under realistic settings, 3) have only one ground truth and one query image for each identity (close environment). To tackle these problems, the proposed Market-1501 dataset is featured in three aspects. First, it contains over 32,000 annotated bboxes, plus a distractor set of over 500K images, making it the largest person re-id dataset to date. Second, images in Market-1501 dataset are produced using the Deformable Part Model (DPM) as pedestrian detector. Third, our dataset is collected in an open system, where each identity has multiple images under each camera. As a minor contribution, inspired by recent advances in large-scale image search, this paper proposes an unsupervised Bag-of-Words descriptor. We view person re-identification as a special task of image search. In experiment, we show that the proposed descriptor yields competitive accuracy on VIPeR, CUHK03, and Market-1501 datasets, and is scalable on the large-scale 500k dataset.},
  keywords={Cameras;Detectors;Visualization;Benchmark testing;Open systems;Boosting;Measurement},
  doi={10.1109/ICCV.2015.133},
  ISSN={2380-7504},
  month={Dec}
}
@misc{CountTrack2025,
	author = {CountTrack},
	year = {2025},
	title = {{Dwell Time: Understanding customer behavior and increasing sales in retail}},
	url = {https://www.counttrack.com/blog-and-news/dwell-time-understanding-customer-behavior-and-increasing-sales-in-retail},
}
@misc{Carden2025,
	author = {Carden, Frances},
	month = {3},
	title = {{Usability}},
	year = {2025},
	url = {https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html},
}
@misc{Admin2023,
	author = {Admin},
	month = {5},
	title = {{DeepSORT: SORT with a Deep Association Metric}},
	year = {2023},
	url = {https://www.luffca.com/2023/05/multiple-object-tracking-DeepSORT/},
}
@misc{BPlanAI2025,
	author = {BPlanAI},
	month = {4},
	title = {{What are the Top 7 KPIs for an In-Store Marketing Agency Business?}},
	year = {2025},
	url = {https://bplan.ai/blogs/kpi-metrics/in-store-marketing-agency-kpi-metrics?utm_source=chatgpt.com},
}








